---
title: "Regression analysis IDEX"
author: "Sietse"
date: "12-5-2022"
output: pdf_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#1 libraries

First, we load in the libraries needed for this project.

```{r}
library(ggplot2)
library(corrplot)
library(dplyr)
library(lubridate)
library(zoo)
library(olsrr)
library(data.table)
library(qqplotr)
library(VARtests)
library(tidyr)
library(remotes)
library(het.test)
library(TSA)
library(lmtest)
library(padr)
library(sandwich)
library(xtable)
library(knitr)
library(vars)
library(Hmisc)
library(car)
library(psych)
library(pander)
library(ggpubr)
library(tidyverse)
library(cowplot)
library(gridExtra)
library(stargazer)
library(tseries)
library(urca)
library(ggthemes)
library(bruceR)
library(forecast)
library(deSolve)
library(tsDyn)
library(apaTables)
```



#2. Data

Let us load in the daily wash trading volume.
For this, one needs the "IDEX_WTvolume.csv" which I made earlier in the prewash_file.
```{r}
IDEX_WTvolume <- read.csv("IDEX_WTvolume.csv")
IDEX_WTvolume$Date <- as.Date(IDEX_WTvolume$day)
IDEX_WTvolume2 <- pad(IDEX_WTvolume)
IDEX_WTvolume3 <- subset(IDEX_WTvolume2, select = -c(day,DEX))
IDEX_WTvolume3[is.na(IDEX_WTvolume3)] <- 0
rm(IDEX_WTvolume2)
rm(IDEX_WTvolume)

IDEXWTrading <- IDEX_WTvolume3 %>% slice(1:677)
IDEXWTvolumeplot <- ggplot(IDEXWTrading, aes(x=Date, y=daily_wash_volume)) + geom_line() +ylab("Wash trading volume (USD)") + theme_base()
IDEXWTvolumeplot
```


Then, we can load in the data regarding the explanatory variables (mechanisms)

I start of with the average gas fee, representing the transaction fees mechanism.

```{r}
AverageGasPrice <- read.csv("AverageGasPrice.csv")
AverageGasP <- subset(AverageGasPrice, select = -c(UnixTimeStamp,Date.UTC.))
AverageGasPRICE <- AverageGasP %>% slice(810:1486)
```

Now let us load in the data for the explanatory variables which represent the hiding mechanism.
All three datasets are Google Trends proxies. One can replicate the csv files using the GT_prep file.

Regarding the variables:
IDEXIDEXtrend is IDEX popularity.
IDEXCYpoptrend is the cybercrime popularity.
IDEXWTtrend is the wash trading popularity.

```{r}

IDEXIDEXtrend2 <- read.csv("DailyTrendIDEXslice.csv")
IDEXIDEXtrend <- IDEXIDEXtrend2 %>% slice(1:677)

IDEXCYpoptrend2 <- read.csv("DailyTrendIDEXCypopslice.csv")
IDEXCYpoptrend <- IDEXCYpoptrend2 %>% slice(1:677)

IDEXWTtrend2 <- read.csv("DailyTrendIDEXWTslice.csv")
IDEXWTtrend <- IDEXWTtrend2 %>% slice(1:677)
```



Finally, let us load in the data for the explanatory variables which represent the sentiment mechanism. 

Regarding the variables:
IDEXETHtrend stands for Ethereum popularity.
EthertradvolIDEX stands for Ethereum trading volume.

Ethereum popularity
```{r}
IDEXETHtrend2 <- read.csv("DailyTrendIDEXETHslice.csv")
IDEXETHtrend <- IDEXETHtrend2 %>% slice(1:677)
```

Ethereum trading volume
```{r}
#MAKE ETHEREUM TRADING VOLUME
EthertradvolIDEX <- read.csv("Investing.comIDEX.csv")
colnames(EthertradvolIDEX)[1] <- gsub('^...','',colnames(EthertradvolIDEX)[1])
EthertradvolIDEX$Date <- mdy(EthertradvolIDEX$Date)

EthertradvolIDEX$Vol. <- dplyr::case_when(
  stringr::str_detect(EthertradvolIDEX$Vol., 'M') ~ readr::parse_number(EthertradvolIDEX$Vol.) * 1e6,
  stringr::str_detect(EthertradvolIDEX$Vol., 'K') ~ readr::parse_number(EthertradvolIDEX$Vol.) * 1e3,
  TRUE ~ parse_number(EthertradvolIDEX$Vol.)
)

EthertradvolIDEX2 <-EthertradvolIDEX %>% slice(256:932)
ETHTVOLIDEX <-subset(EthertradvolIDEX2, select = -c(Price,Open, High, Low, Change..))

```




We can now combine the wash trading volumes and the explanatory variables in one large dataset.
Note that I also make a LOGIDEX file, in which I put the power-transformed variables, such that they are ready for linear regression analyses.

```{r}
IDEX <- IDEXWTrading
names(IDEX)[names(IDEX) == "daily_wash_volume"] <- "WT"
IDEX$Agas <- AverageGasPRICE$Value..Wei.

IDEX$IDEXpop <- IDEXIDEXtrend$est_hits
IDEX$Cypop <- IDEXCYpoptrend$est_hits
IDEX$WTpop <- IDEXWTtrend$est_hits

IDEX$ETHpop <- IDEXETHtrend$est_hits
IDEX$ETHvol <- ETHTVOLIDEX$Vol.

LWT <- log(IDEX$WT + 1)
LAgas <- log(IDEX$Agas + 1)
LIDEXpop <- log(IDEX$IDEXpop + 1)
LCypop <- log(IDEX$Cypop + 1)
LWTpop <- log(IDEX$WTpop + 1)
LETHpop <- log(IDEX$ETHpop + 1)
LETHvol <- log(IDEX$ETHvol + 1)

LOGIDEX = data.frame(LWT=LWT,LAgas=LAgas,LIDEXpop=LIDEXpop, LCypop=LCypop, LWTpop=LWTpop, LETHpop=LETHpop, LETHvol=LETHvol)
```

#3. Analysis
Now we can perform the analyses. First, we start with the correlation analysis, then the multiple linear regressions, and finally the VAR model.

The correlation analysis:

```{r}
IDEXCOR <- subset(IDEX, select = -c(Date))
mcorGOX<-round(cor(IDEXCOR, method = "kendall"),2)
upperGOX<-mcorGOX
upperGOX[upper.tri(mcorGOX)]<-""
upperGOX<-as.data.frame(upperGOX)
upperGOX
print(xtable(upperGOX), type="latex")
```



The multiple regression analysis section contains quite some code. Mainly because I also made regressions including lagged variables.

I start with the six regressions without lag:

```{r}
Reg1 <- lm(IDEX$WT~IDEX$Agas+IDEX$IDEXpop+IDEX$ETHpop)

Reg2 <- lm(IDEX$WT~IDEX$Agas+IDEX$IDEXpop+IDEX$ETHvol)

Reg3 <- lm(IDEX$WT~IDEX$Agas+IDEX$Cypop+IDEX$ETHpop)

Reg4 <- lm(IDEX$WT~IDEX$Agas+IDEX$Cypop+IDEX$ETHvol)

Reg5 <- lm(IDEX$WT~IDEX$Agas+IDEX$WTpop+IDEX$ETHpop)

Reg6 <- lm(IDEX$WT~IDEX$Agas+IDEX$WTpop+IDEX$ETHvol)

stargazer(Reg1, Reg2, Reg3, Reg4, Reg5, Reg6, type = "text")

par(mfrow = c(2,2))
plot(Reg2)
```

I find that the linear regression model contains extreme values, heteroskedasticity, non-linearity and non-normality. Therefore, I power-transformed the variables. I will use the log variables in the further regressions.

```{r}
#LOG regressions

LReg1 <- lm(LWT~LAgas+LIDEXpop+LETHpop, data = LOGIDEX)

LReg2 <- lm(LWT~LAgas+LIDEXpop+LETHvol, data = LOGIDEX)

LReg3 <- lm(LWT~LAgas+LCypop+LETHpop, data = LOGIDEX)

LReg4 <- lm(LWT~LAgas+LCypop+LETHvol, data = LOGIDEX)

LReg5 <- lm(LWT~LAgas+LWTpop+LETHpop, data = LOGIDEX)

LReg6 <- lm(LWT~LAgas+LWTpop+LETHvol, data = LOGIDEX)

#Model fit, diagnostics and heteroskedasticity check
summary(LReg6)
par(mfrow = c(2,2))
plot(LReg4)
durbinWatsonTest(LReg3)

#HAC standard errors
LReg1HAC <- coeftest(LReg1, vcov = vcovHAC(LReg1))
LReg2HAC <- coeftest(LReg2, vcov = vcovHAC(LReg2))
LReg3HAC <- coeftest(LReg3, vcov = vcovHAC(LReg3))
LReg4HAC <- coeftest(LReg4, vcov = vcovHAC(LReg4))
LReg5HAC <- coeftest(LReg5, vcov = vcovHAC(LReg5))
LReg6HAC <- coeftest(LReg6, vcov = vcovHAC(LReg6))

#Output
stargazer(LReg1HAC, LReg2HAC, LReg3HAC, LReg4HAC, LReg5HAC, LReg6HAC, type = "text", out = "C:/users/chess/documents/Thesis_Master/IDEX4regNOLAG.tex")
```


Now I will make six similar regressions, but in these regressions, the explanatory variable is lagged by one period.

First, I lag the variables.
```{r}
LOGIDEX1<- LOGIDEX %>% dplyr::mutate(LLAgas = dplyr::lag(LAgas, n=1, default = NA)) %>% as.data.frame

LOGIDEX2<- LOGIDEX1 %>% dplyr::mutate(LLIDEXpop = dplyr::lag(LIDEXpop, n=1, default = NA)) %>% as.data.frame

LOGIDEX3<- LOGIDEX2 %>% dplyr::mutate(LLCypop = dplyr::lag(LCypop, n=1, default = NA)) %>% as.data.frame

LOGIDEX4<- LOGIDEX3 %>% dplyr::mutate(LLWTpop = dplyr::lag(LWTpop, n=1, default = NA)) %>% as.data.frame

LOGIDEX5<- LOGIDEX4 %>% dplyr::mutate(LLETHpop = dplyr::lag(LETHpop, n=1, default = NA)) %>% as.data.frame

LOGIDEX6<- LOGIDEX5 %>% dplyr::mutate(LLETHvol = dplyr::lag(LETHvol, n=1, default = NA)) %>% as.data.frame


LagIDEX <- LOGIDEX6 %>% slice(2:695)
```


Then we make new regressions with explanatory variables which are lagged one period (one day).

```{r}

Reg1LAG <- lm(LagIDEX$LWT~LagIDEX$LLAgas+LagIDEX$LLIDEXpop+LagIDEX$LLETHpop)

Reg2LAG <- lm(LagIDEX$LWT~LagIDEX$LLAgas+LagIDEX$LLIDEXpop+LagIDEX$LLETHvol)

Reg3LAG <- lm(LagIDEX$LWT~LagIDEX$LLAgas+LagIDEX$LLCypop+LagIDEX$LLETHpop)

Reg4LAG <- lm(LagIDEX$LWT~LagIDEX$LLAgas+LagIDEX$LLCypop+LagIDEX$LLETHvol)

Reg5LAG <- lm(LagIDEX$LWT~LagIDEX$LLAgas+LagIDEX$LLWTpop+LagIDEX$LLETHpop)

Reg6LAG <- lm(LagIDEX$LWT~LagIDEX$LLAgas+LagIDEX$LLWTpop+LagIDEX$LLETHvol)

#HAC
Reg1LHAC <- coeftest(Reg1LAG, vcov = vcovHAC(Reg1LAG))
Reg2LHAC <- coeftest(Reg2LAG, vcov = vcovHAC(Reg2LAG))
Reg3LHAC <- coeftest(Reg3LAG, vcov = vcovHAC(Reg3LAG))
Reg4LHAC <- coeftest(Reg4LAG, vcov = vcovHAC(Reg4LAG))
Reg5LHAC <- coeftest(Reg5LAG, vcov = vcovHAC(Reg5LAG))
Reg6LHAC <- coeftest(Reg6LAG, vcov = vcovHAC(Reg6LAG))

stargazer(Reg1LHAC, Reg2LHAC, Reg3LHAC, Reg4LHAC, Reg5LHAC, Reg6LHAC, type = "text", out = "C:/users/chess/documents/Thesis_Master/IDEXHAC1LAG.tex")
```


Now the same process for six regressions in which the variables are linked seven periods.

First, we lag the variables:

```{r}
WLIDEX1 <- LagIDEX %>% dplyr::mutate(WLAgas = dplyr::lag(LLAgas, n=7, default = NA)) %>% as.data.frame

WLIDEX2<- WLIDEX1 %>% dplyr::mutate(WLIDEXpop = dplyr::lag(LLIDEXpop, n=7, default = NA)) %>% as.data.frame

WLIDEX3<- WLIDEX2 %>% dplyr::mutate(WLCypop = dplyr::lag(LLCypop, n=7, default = NA)) %>% as.data.frame

WLIDEX4<- WLIDEX3 %>% dplyr::mutate(WLWTpop = dplyr::lag(LLWTpop, n=7, default = NA)) %>% as.data.frame

WLIDEX5<- WLIDEX4 %>% dplyr::mutate(WLETHpop = dplyr::lag(LLETHpop, n=7, default = NA)) %>% as.data.frame

WLIDEX6<- WLIDEX5 %>% dplyr::mutate(WLETHvol = dplyr::lag(LLETHvol, n=7, default = NA)) %>% as.data.frame



WLIDEX <- WLIDEX6 %>% slice(8:695)

```



Then we make six regressions with explanatory variables which are lagged seven periods (seven days).

```{r}
Reg1WL <- lm(WLIDEX$LWT~WLIDEX$WLAgas+WLIDEX$WLIDEXpop+WLIDEX$WLETHpop)

Reg2WL <- lm(WLIDEX$LWT~WLIDEX$WLAgas+WLIDEX$WLIDEXpop+ WLIDEX$WLETHvol)

Reg3WL <- lm(WLIDEX$LWT~WLIDEX$WLAgas+WLIDEX$WLCypop+WLIDEX$WLETHpop)

Reg4WL <- lm(WLIDEX$LWT~WLIDEX$WLAgas+WLIDEX$WLCypop+ WLIDEX$WLETHvol)

Reg5WL <- lm(WLIDEX$LWT~WLIDEX$WLAgas+WLIDEX$WLWTpop+WLIDEX$WLETHpop)

Reg6WL <- lm(WLIDEX$LWT~WLIDEX$WLAgas+WLIDEX$WLWTpop+ WLIDEX$WLETHvol)

#HAC
Reg1WLHAC <- coeftest(Reg1WL, vcov = vcovHAC(Reg1WL))
Reg2WLHAC <- coeftest(Reg2WL, vcov = vcovHAC(Reg2WL))
Reg3WLHAC <- coeftest(Reg3WL, vcov = vcovHAC(Reg3WL))
Reg4WLHAC <- coeftest(Reg4WL, vcov = vcovHAC(Reg4WL))
Reg5WLHAC <- coeftest(Reg5WL, vcov = vcovHAC(Reg5WL))
Reg6WLHAC <- coeftest(Reg6WL, vcov = vcovHAC(Reg6WL))

stargazer(Reg1WLHAC, Reg2WLHAC, Reg3WLHAC, Reg4WLHAC, Reg5WLHAC, Reg6WLHAC, type = "text", out = "C:/users/chess/documents/Thesis_Master/IDEXHAC7LAG.tex")
``` 


Finally, I create and analyze a VAR model. 

To not overcomplicate this analysis, I chose the most intuitive explanatory variables to represent their mechanisms. For transaction fees, I use averages gas fees (Agas). For the hiding mechanism, wash trading popularity. For the sentiment mechanisms, I use Ethereum popularity.

It is important for VAR models to check stationarity first. The normal (non-log) variables are I(1), that is, they are not stationary in levels but stationary in the first difference.

However, the log variables are stationary, and therefore, we will run a VAR model including these variables.

Stationary tests:
```{r}
VARIDEX <- subset(IDEXCOR, select = -c(IDEXpop, Cypop, ETHvol))
view(VARIDEX)
adf.test(VARED$WT)
adf.test(VARED$AGas)
adf.test(VARED$CYPOP)
adf.test(VARED$TRENDETH)

kpss.test(VARED$WT)
kpss.test(VARED$AGas)
kpss.test(VARED$CYPOP)
kpss.test(VARED$TRENDETH)

LOGVAR = data.frame(LWT=LWT,LAgas=LAgas, LWTpop=LWTpop, LETHpop=LETHpop)
adf.test(LOGVAR$LWT)
adf.test(LOGVAR$LAgas)
adf.test(LOGVAR$LCypop)
adf.test(LOGVAR$LETHpop)

kpss.test(LOGVAR$LWT)
kpss.test(LOGVAR$LAgas)
kpss.test(LOGVAR$LCypop)
kpss.test(LOGVAR$LETHpop)
```

After selecting the variables and checking the stationarity of the variables, we select the optimal lag. 

```{r}
IDEXLAG <- VARselect(LOGVAR, lag.max = 12, type = "const")
IDEXLAG
```

I find that 3 lags is optimal.

Now we estimate the VAR model.

```{r}
VARModel <- VAR(LOGVAR, p= 3, type="const", season = NULL, exog = NULL)
summary(VARModel)
xtable(VARModel$varresult$LWT)
```

Now we can run some diagnostics to test the model.
```{r}
#Serial correlation
#AUTOCORRELATION 
SerialED <- serial.test(VARModel, lags.pt = 12, type = "PT.asymptotic")
SerialED

#(CONDITIONAL) HETEROSKEDASTICITY 
ARCHED <- arch.test(VARModel, lags.multi = 12, multivariate.only = TRUE)
ARCHED
  
#NORMALITY TESTS
NORMED <- normality.test(VARModel, multivariate.only = TRUE)
NORMED

#STABILITY TESTS
#ROOT TEST
print(roots(VAR(LOGVAR, p=10), modulus = TRUE))

#STRUCTURAL BREAKS TEST
STABED <- stability(VAR(LOGVAR, p=3), type = "OLS-CUSUM")
plot(STABED)
```

Next, we test for Granger causality:
```{r}
Granger1<-granger_causality(VARModel)
```


Finally, we can make the impulse response function graphs:
```{r}
EDWASHTF <- irf(VARModel, impulse = "LAgas", response = "LWT", n.ahead = 20, boot = TRUE)
plot(EDWASHTF, ylab = "Log(WT)", main = "Log transaction fee shock to Wash trading volume (IDEX)")

EDWASHCy <- irf(VARModel, impulse = "LWTpop", response = "LWT", n.ahead = 20, boot = TRUE)
plot(EDWASHCy, ylab = "Log(WT)", main = "Log wash trading popularity shock to Wash trading volume (IDEX)")

EDWASHETHPOP <- irf(VARModel, impulse = "LETHpop", response = "LWT", n.ahead = 20, boot = TRUE)
plot(EDWASHETHPOP, ylab = "Log(WT)", main = "Log Ethereum popularity shock to Wash trading volume (IDEX)")

```



